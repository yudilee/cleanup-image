{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Cleanup Image Backend - Google Colab Setup\n",
                "\n",
                "This notebook runs the backend on a free Google Colab GPU (T4) and exposes it via ngrok.\n",
                "\n",
                "## Quick Start:\n",
                "1. **Runtime Type**: Ensure you are using a GPU Runtime (Runtime > Change runtime type > T4 GPU).\n",
                "2. **Ngrok Token**: You need a free account at [ngrok.com](https://dashboard.ngrok.com/get-started/your-authtoken).\n",
                "\n",
                "> **‚ö†Ô∏è IMPORTANT**: During installation (Step 3), Colab might ask you to **\"Restart session\"**. \n",
                "> This is **NORMAL**. Click **\"Restart session\"**, then run the cells again. \n",
                "> (The installation cell might show errors about 'dependency resolver' - you can ignore these generally as long as our app works)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Clone Repository\n",
                "!git clone https://github.com/yudilee/cleanup-image.git\n",
                "%cd cleanup-image/backend"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Install System Dependencies\n",
                "!apt-get update && apt-get install -y libgl1-mesa-glx libhl-amdgpu-pro"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Install Python Dependencies\n",
                "# NOTE: This may downgrade NumPy and ask for a session restart. \n",
                "# If asked, click 'Restart session', then run this cell again (it will be fast) and proceed.\n",
                "!pip install -r requirements.txt\n",
                "!pip install pyngrok uvicorn nest_asyncio"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Install PixelHacker Dependencies (Optional - for high quality model)\n",
                "# Uncomment the lines below if you want to use the PixelHacker model\n",
                "# !pip install diffusers==0.30.2 transformers==4.40.0 accelerate==0.34.0 peft"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Setup Ngrok & Run Server\n",
                "import getpass\n",
                "import os\n",
                "import sys\n",
                "import subprocess\n",
                "from pyngrok import ngrok, conf\n",
                "\n",
                "# Get Ngrok Token\n",
                "print(\"Please enter your Ngrok Authtoken (from https://dashboard.ngrok.com/get-started/your-authtoken):\")\n",
                "try:\n",
                "    token = getpass.getpass('Ngrok Authtoken: ')\n",
                "except Exception as e:\n",
                "    token = input(\"Ngrok Authtoken: \")\n",
                "\n",
                "if token:\n",
                "    conf.get_default().auth_token = token\n",
                "    \n",
                "    # Kill existing tunnels\n",
                "    ngrok.kill()\n",
                "\n",
                "    # Start tunnel\n",
                "    public_url = ngrok.connect(8000)\n",
                "    print(f\"\\n\\nüöÄ Backend is running! Copy this URL into your Frontend ENV or Code: {public_url}\\n\\n\")\n",
                "    \n",
                "    # Ensure we are in the backend directory\n",
                "    if os.path.basename(os.getcwd()) != 'backend':\n",
                "        if os.path.exists('cleanup-image/backend'):\n",
                "            os.chdir('cleanup-image/backend')\n",
                "        elif os.path.exists('backend'):\n",
                "            os.chdir('backend')\n",
                "    \n",
                "    print(f\"Running server in directory: {os.getcwd()}\")\n",
                "    \n",
                "    # Run Uvicorn as a SUBPROCESS to avoid event loop conflicts in Colab\n",
                "    # This isolates the server process from the notebook's asyncio loop\n",
                "    cmd = [sys.executable, \"-m\", \"uvicorn\", \"main:app\", \"--host\", \"127.0.0.1\", \"--port\", \"8000\"]\n",
                "    \n",
                "    try:\n",
                "        # subprocess.run will block this cell and stream output to the console\n",
                "        subprocess.run(cmd, check=True)\n",
                "    except KeyboardInterrupt:\n",
                "        print(\"Server stopped by user.\")\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Error running server: {e}\")\n",
                "else:\n",
                "    print(\"‚ùå Error: Ngrok token is required to expose the server.\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}